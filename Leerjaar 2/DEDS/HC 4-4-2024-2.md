Deze aantekeningen heb ik door AI laten structureren, helaas heeft die het vertaalt naar het Engels. Ik heb wel gecontroleerd dat alle data er nog steeds in zit. Excuses voor het ongemak.

# Classification Notes
Supervised classification involves categorizing data into classes with dependent values. We have previously covered data preparation and one hot encoding, but it's important to note that these steps are essential for this process. Overfitting occurs when the model learns the training data too well, while underfitting results from using a too simple model to describe the data. Evaluation is assessing how well the model performs, and a confusion matrix indicates the number of true-positives, false-positives, true-negatives, and false-negatives.

Decision trees are a form of explainable AI for discrete data, with dependent variables that can also be discrete. In this case, use classification models instead of regression. When reading a decision tree, you'll notice the condition at the top, with true indicated by a left arrow and false represented by a right arrow. The 'samples' value shows how many training-data samples fall under that set. Gini index measures impurity, and 'value' denotes the number of true and false in this category. The deepest item in the decision tree does not have a condition because it is not further split. If both value-values are roughly equal, no definitive conclusion can be drawn.

Een decision tree classifier maakt het mogelijk om het denkproces te zien.

Hier is een voorbeeld van een decision-tree-classifier in Python:

```py
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Load iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test

# Create Decision Tree Classifier
clf = DecisionTreeClassifier()

# Train Decision Tree Classifier
clf = clf.fit(X_train,y_train)

# Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy
print("Accuracy:",accuracy_score(y_test, y_pred))
```

Voor visualisatie:
```py
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn import tree
import graphviz 

# Load iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test

# Create Decision Tree Classifier
clf = DecisionTreeClassifier()

# Train Decision Tree Classifier
clf = clf.fit(X_train,y_train)

# Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy
print("Accuracy:",accuracy_score(y_test, y_pred))

# Visualize the decision tree
dot_data = tree.export_graphviz(clf, out_file=None, 
                                feature_names=iris.feature_names,  
                                class_names=iris.target_names,
                                filled=True)

# Draw graph
graph = graphviz.Source(dot_data, format="png") 
graph
```

Horizontaal snijden: kiezen wat je wil voorspellen.
Vertikaal snijden: test-train split.

<img src="./1.heic" />
